# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨å®šæŠ•ç­–ç•¥åˆ†æåç«¯API
é€‚é…å®å¡”é¢æ¿éƒ¨ç½² | æ”¯æŒFlaskå†…ç½®æœåŠ¡å™¨/uWSGIè¿è¡Œ
ç«¯å£ï¼š8002 | æ ¸å¿ƒæ¥å£ï¼š/api/stock_data /api/analyze_strategy
"""
from flask import Flask, jsonify, request
from flask_cors import CORS
import baostock as bs
import datetime
import time
import numpy as np
import logging
from decimal import Decimal, ROUND_HALF_UP
# æ‹¼éŸ³å¤„ç†ä¾èµ–
from pypinyin import lazy_pinyin, Style
# ç³»ç»Ÿæ¨¡å—ï¼ˆè·¯å¾„é…ç½®ï¼‰
import os

# ====================== 1. åŸºç¡€é…ç½®ï¼ˆé€‚é…å®å¡”è·¯å¾„ï¼‰ ======================
# åç«¯æ ¹ç›®å½•ï¼ˆæ ¹æ®å®é™…éƒ¨ç½²è·¯å¾„è°ƒæ•´ï¼‰
BASE_DIR = "/www/wwwroot/43.138.21.195/backend"
# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(BASE_DIR, exist_ok=True)

# ====================== 2. æ—¥å¿—é…ç½®ï¼ˆå…¼å®¹å®å¡”æŸ¥çœ‹ï¼‰ ======================
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)
# èµ‹äºˆwwwç”¨æˆ·æƒé™ï¼ˆå®å¡”è¿è¡Œç”¨æˆ·ï¼‰
try:
    os.chmod(LOG_DIR, 0o755)
    if os.path.exists("/usr/bin/chown"):
        os.system(f"chown www:www {LOG_DIR}")
except Exception as e:
    print(f"æ—¥å¿—ç›®å½•æƒé™è®¾ç½®è­¦å‘Šï¼š{e}")

# æ—¥å¿—æ ¼å¼é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y/%m/%d %H:%M:%S',
    handlers=[
        logging.FileHandler(os.path.join(LOG_DIR, "stock_api.log"), encoding="utf-8"),
        logging.StreamHandler()  # ç»ˆç«¯è¾“å‡ºï¼Œæ–¹ä¾¿è°ƒè¯•
    ]
)
logger = logging.getLogger(__name__)

# ====================== 3. Flaskåº”ç”¨åˆå§‹åŒ– ======================
app = Flask(__name__)
# è·¨åŸŸé…ç½®ï¼šå…è®¸æ‰€æœ‰åŸŸå+æºå¸¦å‡­è¯ï¼ˆé€‚é…å‰ç«¯è¯·æ±‚ï¼‰
CORS(app, resources=r"/*", supports_credentials=True)

# ====================== 4. è‚¡ç¥¨åç§°-ä»£ç æ˜ å°„è¡¨ ======================
STOCK_NAME_MAP = {
    "è´µå·èŒ…å°": "sh.600519",
    "å®å¾·æ—¶ä»£": "sz.300750",
    "è…¾è®¯æ§è‚¡": "hk.00700",
    "æ¯”äºšè¿ª": "sz.002594",
    "ä¸­å›½å¹³å®‰": "sh.601318",
    "æ‹›å•†é“¶è¡Œ": "sh.600036",
    "äº”ç²®æ¶²": "sz.000858",
    "éš†åŸºç»¿èƒ½": "sh.601012",
    "è¿ˆç‘åŒ»ç–—": "sz.300760",
    "æ’ç‘åŒ»è¯": "sh.600276",
    "ä¸­ä¿¡è¯åˆ¸": "sh.600030",
    "ä¸œæ–¹è´¢å¯Œ": "sz.300059",
    "ç«‹è®¯ç²¾å¯†": "sz.002475",
    "æ³¸å·è€çª–": "sz.000568",
    "å…†æ˜“åˆ›æ–°": "sh.603986",
    "é»‘ç‰¡ä¸¹": "sh.600510",
}
# åå‘æ˜ å°„ï¼šä»£ç â†’åç§°
CODE_TO_STOCK_NAME = {v: k for k, v in STOCK_NAME_MAP.items()}

# ====================== 5. å·¥å…·å‡½æ•° ======================
def to_valid_date(date_str):
    """è½¬æ¢ä¸ºæœ‰æ•ˆæ—¥æœŸå¯¹è±¡ï¼Œå…¼å®¹å¤šç§æ ¼å¼"""
    if not date_str:
        raise ValueError("æ—¥æœŸä¸èƒ½ä¸ºç©º")
    try:
        clean_str = date_str.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "").replace(".", "-").replace("/", "-")
        return datetime.datetime.strptime(clean_str, "%Y-%m-%d").date()
    except Exception as e:
        raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯ï¼š{date_str}ï¼Œé”™è¯¯ï¼š{str(e)}")

def get_iso_week(date_obj):
    """è·å–ISOå‘¨æ•°ï¼ˆå¹´+å‘¨ï¼‰"""
    week_num = date_obj.isocalendar()[1]
    return f"{date_obj.year}{week_num:02d}"

def round_decimal(value, decimal_places=2):
    """ç²¾å‡†å››èˆäº”å…¥"""
    return float(Decimal(str(value)).quantize(Decimal(f"0.{'0'*decimal_places}"), rounding=ROUND_HALF_UP))

def get_pinyin_first_letter(chinese_str):
    """æå–ä¸­æ–‡å­—ç¬¦ä¸²æ‹¼éŸ³é¦–å­—æ¯ï¼ˆå¤§å†™ï¼‰"""
    if not chinese_str or not isinstance(chinese_str, str):
        return ""
    try:
        pinyin_list = lazy_pinyin(chinese_str, style=Style.FIRST_LETTER)
        return ''.join([p.upper() for p in pinyin_list])
    except Exception as e:
        logger.error(f"æå–æ‹¼éŸ³é¦–å­—æ¯å¤±è´¥ï¼š{e}")
        return ""

def generate_name_first_letter_map():
    """ç”Ÿæˆè‚¡ç¥¨åç§°â†’æ‹¼éŸ³é¦–å­—æ¯æ˜ å°„è¡¨"""
    name_letter_map = {}
    for name, code in STOCK_NAME_MAP.items():
        first_letters = get_pinyin_first_letter(name)
        name_letter_map[name] = {
            "code": code,
            "first_letter": first_letters,
            "is_hk": code.startswith("hk.")
        }
    return name_letter_map
# åˆå§‹åŒ–é¦–å­—æ¯æ˜ å°„è¡¨
NAME_FIRST_LETTER_MAP = generate_name_first_letter_map()

def get_stock_name_from_baostock(code):
    """ä»Baostockå®æ—¶æŸ¥è¯¢è‚¡ç¥¨åç§°ï¼ˆå…œåº•ç”¨ï¼‰"""
    if not code or not (code.startswith("sh.") or code.startswith("sz.")):
        return None
    try:
        lg = bs.login()
        if lg.error_code != '0':
            logger.warning(f"Baostockç™»å½•å¤±è´¥ï¼š{lg.error_msg}")
            bs.logout()
            return None
        
        rs = bs.query_stock_basic(code=code)
        if rs.error_code != '0':
            logger.warning(f"æŸ¥è¯¢{code}åŸºæœ¬ä¿¡æ¯å¤±è´¥ï¼š{rs.error_msg}")
            bs.logout()
            return None
        
        stock_name = None
        if rs.next():
            row_data = rs.get_row_data()
            if len(row_data) >= 2:
                stock_name = row_data[1]
        
        bs.logout()
        return stock_name if stock_name else None
    except Exception as e:
        logger.error(f"ä»Baostockè·å–{code}åç§°å¤±è´¥ï¼š{e}", exc_info=True)
        try:
            bs.logout()
        except:
            pass
        return None

def fuzzy_match_stock_by_name(input_name):
    """æ¨¡ç³ŠåŒ¹é…è‚¡ç¥¨åç§°"""
    if not input_name:
        return []
    input_name = input_name.strip()
    matched_list = []
    for name, code in STOCK_NAME_MAP.items():
        if input_name in name:
            matched_list.append({
                "name": name,
                "code": code,
                "is_hk": code.startswith("hk.")
            })
    matched_list.sort(key=lambda x: len(x["name"]))
    return matched_list

def match_stock_by_first_letter(input_letter):
    """é€šè¿‡æ‹¼éŸ³é¦–å­—æ¯åŒ¹é…è‚¡ç¥¨"""
    if not input_letter:
        return []
    input_letter = input_letter.strip().upper()
    matched_list = []
    for name, info in NAME_FIRST_LETTER_MAP.items():
        if info["first_letter"].startswith(input_letter) or info["first_letter"] == input_letter:
            matched_list.append({
                "name": name,
                "code": info["code"],
                "first_letter": info["first_letter"],
                "is_hk": info["is_hk"]
            })
    matched_list.sort(key=lambda x: (x["first_letter"] != input_letter, len(x["first_letter"])))
    return matched_list

def match_stock_code(input_str):
    """é€šç”¨åŒ¹é…ï¼ˆä»£ç /åç§°/é¦–å­—æ¯ï¼‰"""
    if not input_str:
        return None, False
    input_str = input_str.strip()
    
    # 1. å®Œæ•´ä»£ç åŒ¹é…
    is_hk = input_str.startswith('hk.')
    if input_str.startswith(('sh.', 'sz.', 'hk.')):
        logger.info(f"åŒ¹é…åˆ°å®Œæ•´ä»£ç ï¼š{input_str}ï¼ˆæ¸¯è‚¡ï¼š{is_hk}ï¼‰")
        return input_str, is_hk
    
    # 2. çº¯æ•°å­—è¡¥å‰ç¼€
    if input_str.isdigit():
        if input_str.startswith(('60', '68')):
            code = f"sh.{input_str}"
            return code, False
        elif input_str.startswith(('00', '30')):
            code = f"sz.{input_str}"
            return code, False
        elif len(input_str) == 5:
            code = f"hk.{input_str}"
            return code, True
    
    # 3. é¦–å­—æ¯åŒ¹é…
    letter_matched = match_stock_by_first_letter(input_str)
    if letter_matched:
        logger.info(f"é¦–å­—æ¯åŒ¹é…ï¼š{input_str} â†’ {letter_matched[0]['name']}ï¼ˆ{letter_matched[0]['code']}ï¼‰")
        return letter_matched[0]["code"], letter_matched[0]["is_hk"]
    
    # 4. æ¨¡ç³Šåç§°åŒ¹é…
    name_matched = fuzzy_match_stock_by_name(input_str)
    if name_matched:
        logger.info(f"æ¨¡ç³Šåç§°åŒ¹é…ï¼š{input_str} â†’ {name_matched[0]['name']}ï¼ˆ{name_matched[0]['code']}ï¼‰")
        return name_matched[0]["code"], name_matched[0]["is_hk"]
    
    return None, False

# ====================== 6. è‚¡ç¥¨æ•°æ®è·å–å‡½æ•° ======================
def calculate_pe_quantile(pe_list):
    """è®¡ç®—PEåˆ†ä½ç‚¹"""
    quantiles = [0.0] * len(pe_list)
    if len(pe_list) < 21:
        logger.warning("PEæ•°æ®é‡ä¸è¶³21æ¡ï¼Œåˆ†ä½ç‚¹è®¡ç®—ç»“æœä¸º0")
        return quantiles
    
    for i in range(20, len(pe_list)):
        try:
            current_pe = pe_list[i]
            if current_pe <= 0:
                continue
            valid_history = [x for x in pe_list[:i+1] if x > 0]
            if len(valid_history) < 5:
                continue
            percentiles = np.percentile(valid_history, np.arange(0, 101))
            q = np.searchsorted(percentiles, current_pe) / 100.0
            quantiles[i] = round_decimal(min(q * 100, 100.0), 2)
        except Exception as e:
            logger.error(f"è®¡ç®—åˆ†ä½ç‚¹å¤±è´¥(i={i})ï¼š{e}")
    return quantiles

def get_epsTTM_data(code, start_year, end_year):
    """è·å–epsTTMè´¢åŠ¡æ•°æ®"""
    eps_ttm_map = {}
    logger.info(f"å¼€å§‹æŸ¥è¯¢{code}çš„epsTTMï¼šå¹´ä»½èŒƒå›´{start_year-2}-{end_year}")
    try:
        query_years = range(start_year - 2, end_year + 1)
        for year in query_years:
            for quarter in [1, 2, 3, 4]:
                rs = bs.query_finance_indicator(code=code, year=year, quarter=quarter)
                if rs.error_code != '0':
                    logger.warning(f"[{code}] {year}å¹´Q{quarter} epsTTMæŸ¥è¯¢å¤±è´¥ï¼š{rs.error_msg}")
                    continue
                row_count = 0
                while rs.next():
                    row_count += 1
                    row = rs.get_row_data()
                    if row_count == 1:
                        logger.debug(f"[{code}] è´¢åŠ¡æ¥å£è¿”å›å­—æ®µï¼š{rs.fields}")
                    if "epsTTM" in rs.fields:
                        eps_ttm_idx = rs.fields.index("epsTTM")
                        eps_ttm = row[eps_ttm_idx] if eps_ttm_idx < len(row) else None
                    else:
                        eps_ttm = None
                        logger.warning(f"[{code}] {year}å¹´Q{quarter} æ— epsTTMå­—æ®µ")
                    
                    if eps_ttm and eps_ttm != 'None' and eps_ttm != '':
                        key = f"{year}-Q{quarter}"
                        eps_ttm_map[key] = float(eps_ttm)
                        logger.debug(f"[{code}] {key} epsTTMï¼š{eps_ttm_map[key]}")
        if not eps_ttm_map:
            logger.error(f"[{code}] æœªæŸ¥è¯¢åˆ°ä»»ä½•epsTTMæ•°æ®")
        else:
            logger.info(f"[{code}] æˆåŠŸæŸ¥è¯¢åˆ°{len(eps_ttm_map)}æ¡epsTTMæ•°æ®")
        return eps_ttm_map
    except Exception as e:
        logger.error(f"[{code}] è·å–epsTTMæ•°æ®å¼‚å¸¸ï¼š{e}", exc_info=True)
        return eps_ttm_map

def match_epsTTM_by_date(date_str, eps_ttm_map, code):
    """åŒ¹é…æ—¥æœŸå¯¹åº”çš„epsTTM"""
    if not eps_ttm_map:
        logger.warning(f"[{code}] æ— epsTTMæ•°æ®å¯åŒ¹é…æ—¥æœŸï¼š{date_str}")
        return 0.0
    try:
        date_obj = to_valid_date(date_str)
        year = date_obj.year
        month = date_obj.month
        
        quarter = "Q1" if month in [1,2,3] else "Q2" if month in [4,5,6] else "Q3" if month in [7,8,9] else "Q4"
        target_key = f"{year}-{quarter}"
        
        if target_key in eps_ttm_map:
            return eps_ttm_map[target_key]
        else:
            sorted_keys = sorted(eps_ttm_map.keys(), reverse=True)
            for key in sorted_keys:
                return eps_ttm_map[key]
        return 0.0
    except Exception as e:
        logger.error(f"[{code}] åŒ¹é…epsTTMæ—¥æœŸå¤±è´¥ï¼š{e}", exc_info=True)
        return 0.0

def get_stock_data(code, start_date, end_date, is_hk=False):
    """è·å–è‚¡ç¥¨åŸºç¡€æ•°æ®ï¼ˆä¸»å‡½æ•°ï¼‰"""
    retry_times = 3
    for retry in range(retry_times):
        lg = None
        try:
            lg = bs.login()
            if lg.error_code != '0':
                raise Exception(f"ç™»å½•å¤±è´¥ï¼š{lg.error_msg}")
            
            query_fields = "date,close,peTTM"
            rs = bs.query_history_k_data_plus(
                code,
                query_fields,
                start_date=start_date,
                end_date=end_date,
                frequency="d",
                adjustflag="1"
            )
            
            if rs.error_code != '0':
                raise Exception(f"æŸ¥è¯¢å¤±è´¥ï¼š{rs.error_msg}")
            
            data_list = []
            pe_list = []
            while rs.next():
                row = rs.get_row_data()
                date = row[0]
                if not date:
                    continue
                close = float(row[1]) if (row[1] and row[1] != 'None') else 0.0
                pe = float(row[2]) if (row[2] and row[2] != 'None') else 0.0
                
                data_item = {
                    "æ—¥æœŸ": date,
                    "æ”¶ç›˜ä»·": round_decimal(close, 2),
                    "PE": round_decimal(pe, 2),
                    "æ¯è‚¡ç›ˆåˆ©TTM": None if is_hk else 0.0,
                    "PEåˆ†ä½ç‚¹": 0.0,
                    "å¤‡æ³¨": "æ¸¯è‚¡æš‚ä¸æ”¯æŒepsTTMæŸ¥è¯¢" if is_hk else ""
                }
                data_list.append(data_item)
                pe_list.append(pe)
            
            # è®¡ç®—PEåˆ†ä½ç‚¹
            quantiles = calculate_pe_quantile(pe_list)
            for idx, item in enumerate(data_list):
                item["PEåˆ†ä½ç‚¹"] = quantiles[idx]
            
            # å¡«å……epsTTM
            if not is_hk and data_list:
                start_year = int(start_date[:4])
                end_year = int(end_date[:4])
                eps_ttm_map = get_epsTTM_data(code, start_year, end_year)
                empty_eps_count = 0
                for item in data_list:
                    eps_ttm = match_epsTTM_by_date(item["æ—¥æœŸ"], eps_ttm_map, code)
                    item["æ¯è‚¡ç›ˆåˆ©TTM"] = round_decimal(eps_ttm, 4)
                    if eps_ttm == 0.0:
                        empty_eps_count += 1
                
                # å…œåº•ä¼°ç®—
                if empty_eps_count == len(data_list):
                    logger.warning(f"[{code}] æ— epsTTMæ•°æ®ï¼Œä½¿ç”¨PEä¼°ç®—")
                    for item in data_list:
                        if item["PE"] > 0 and item["æ”¶ç›˜ä»·"] > 0:
                            item["æ¯è‚¡ç›ˆåˆ©TTM"] = round_decimal(item["æ”¶ç›˜ä»·"] / item["PE"], 4)
                            item["å¤‡æ³¨"] = "epsTTMç”±PEå’Œæ”¶ç›˜ä»·ä¼°ç®—"
            
            bs.logout()
            return {
                "code": 200,
                "msg": f"æˆåŠŸè·å–{len(data_list)}æ¡æ•°æ®",
                "data": data_list
            }
        except Exception as e:
            if lg:
                try:
                    bs.logout()
                except:
                    pass
            logger.error(f"é‡è¯•{retry+1}æ¬¡å¤±è´¥ï¼š{e}")
            if retry == retry_times - 1:
                return {"code": 500, "msg": f"è·å–æ•°æ®å¤±è´¥ï¼š{str(e)}", "data": []}
            time.sleep(1)

# ====================== 7. ç­–ç•¥è®¡ç®—å‡½æ•° ======================
def run_strategy(raw_data, params):
    """æ‰§è¡Œå®šæŠ•ç­–ç•¥è®¡ç®—"""
    logs = []
    try:
        # è§£æå‚æ•°
        initial_capital = float(params.get("initialCapital", 10000))
        start_date = to_valid_date(params.get("startDate", "2023-01-01"))
        end_date = to_valid_date(params.get("endDate", datetime.datetime.now().strftime('%Y-%m-%d')))
        invest_amount = float(params.get("investAmount", 1000))
        base_ratio = float(params.get("baseRatio", 50)) / 100
        fee_rate = float(params.get("feeRate", 0.1)) / 100
        pe_lower_quantile = float(params.get("peLowerQuantile", 30))
        pe_upper_quantile = float(params.get("peUpperQuantile", 70))
        
        logs.append("å¼€å§‹è¿è¡Œç­–ç•¥è®¡ç®—ï¼ˆçº¯è‡ªæœ‰èµ„é‡‘ï¼‰...")
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´æ•°æ®
        data = []
        for row in raw_data:
            row_date = to_valid_date(row["æ—¥æœŸ"])
            if start_date <= row_date <= end_date:
                new_row = {
                    "æ—¥æœŸ": row["æ—¥æœŸ"],
                    "æ”¶ç›˜ä»·": row["æ”¶ç›˜ä»·"],
                    "PE": row["PE"],
                    "PEåˆ†ä½ç‚¹": row["PEåˆ†ä½ç‚¹"],
                    "æ¯è‚¡ç›ˆåˆ©TTM": row["æ¯è‚¡ç›ˆåˆ©TTM"],
                    "å¤‡æ³¨": row["å¤‡æ³¨"],
                    
                    # ä¸€æ¬¡æ€§ä¹°å…¥
                    "ä¸€æ¬¡æ€§ä¹°å…¥æ€»èµ„äº§": initial_capital,
                    "ä¸€æ¬¡æ€§ä¹°å…¥æ”¶ç›Šç‡": 0.0,
                    "ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æ”¶ç›Š": 0.0,
                    "ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æŠ•å…¥": initial_capital,
                    
                    # æ™®é€šå®šæŠ•
                    "æ™®é€šå®šæŠ•æ€»èµ„äº§": 0.0,
                    "æ™®é€šå®šæŠ•æ”¶ç›Šç‡": 0.0,
                    "æ™®é€šå®šæŠ•ç´¯è®¡æ”¶ç›Š": 0.0,
                    "æ™®é€šå®šæŠ•ç´¯è®¡æŠ•å…¥": 0.0,
                    
                    # åº•ä»“å®šæŠ•
                    "åº•ä»“å®šæŠ•æ€»èµ„äº§": initial_capital,
                    "åº•ä»“å®šæŠ•æ”¶ç›Šç‡": 0.0,
                    "åº•ä»“å®šæŠ•ç´¯è®¡æ”¶ç›Š": 0.0,
                    "åº•ä»“å®šæŠ•ç´¯è®¡æŠ•å…¥": 0.0,
                    
                    # ä¼°å€¼æ­¢ç›ˆ
                    "ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§": initial_capital,
                    "ä¼°å€¼æ­¢ç›ˆæ€»æ”¶ç›Šç‡": 0.0,
                    "ä¼°å€¼æ­¢ç›ˆç´¯è®¡æ”¶ç›Š": 0.0,
                    "ä¼°å€¼æ­¢ç›ˆç´¯è®¡æŠ•å…¥": 0.0,
                    "ä¼°å€¼æ­¢ç›ˆä»“ä½": 0.0,
                    "ä¼°å€¼æ­¢ç›ˆä¿¡å·": "",
                    "ä¹°å–æ ‡è®°": ""
                }
                data.append(new_row)
        
        if not data:
            raise ValueError("æ—¶é—´èŒƒå›´å†…æ— æœ‰æ•ˆæ•°æ®")
        
        logs.append(f"ç­–ç•¥è®¡ç®—èŒƒå›´ï¼š{start_date} è‡³ {end_date}ï¼Œå…±{len(data)}ä¸ªäº¤æ˜“æ—¥")
        
        # 1. ä¸€æ¬¡æ€§ä¹°å…¥ç­–ç•¥
        buy_once_price = data[0]["æ”¶ç›˜ä»·"]
        buy_once_shares = (initial_capital * (1 - fee_rate)) / buy_once_price
        for row in data:
            row["ä¸€æ¬¡æ€§ä¹°å…¥æ€»èµ„äº§"] = round_decimal(buy_once_shares * row["æ”¶ç›˜ä»·"], 2)
            row["ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æ”¶ç›Š"] = round_decimal(row["ä¸€æ¬¡æ€§ä¹°å…¥æ€»èµ„äº§"] - initial_capital, 2)
            row["ä¸€æ¬¡æ€§ä¹°å…¥æ”¶ç›Šç‡"] = round_decimal(row["ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æ”¶ç›Š"] / initial_capital * 100, 2)
        logs.append(f"âœ… ä¸€æ¬¡æ€§ä¹°å…¥ç­–ç•¥ï¼š{round_decimal(buy_once_shares, 2)}è‚¡ï¼Œä¹°å…¥ä»·{buy_once_price}å…ƒ")
        
        # 2. æ™®é€šå®šæŠ•ç­–ç•¥ï¼ˆä¿®å¤ï¼šå¢åŠ ç°é‡‘é™åˆ¶ï¼Œä»…ç”¨è‡ªæœ‰èµ„é‡‘ï¼‰
        normal_invest_shares = 0.0
        normal_invest_total = 0.0
        normal_invested_weeks = set()
        normal_available_cash = initial_capital  # æ–°å¢ï¼šæ™®é€šå®šæŠ•å¯ç”¨ç°é‡‘ï¼ˆåˆå§‹=æ€»æœ¬é‡‘ï¼‰
        
        for row in data:
            row_date = to_valid_date(row["æ—¥æœŸ"])
            current_week = get_iso_week(row_date)
            
            # æ¯å‘¨å®šæŠ•ï¼ˆå¢åŠ ç°é‡‘é™åˆ¶ï¼šå¯ç”¨ç°é‡‘â‰¥å®šæŠ•é‡‘é¢æ‰å®šæŠ•ï¼‰
            if current_week not in normal_invested_weeks and normal_available_cash >= invest_amount:
                actual_invest = min(invest_amount, normal_available_cash)  # ä¿®å¤ï¼šç¡®ä¿ä¸è¶…å¯ç”¨ç°é‡‘
                buy_amount = actual_invest * (1 - fee_rate)
                normal_invest_shares += buy_amount / row["æ”¶ç›˜ä»·"]
                normal_invest_total += actual_invest
                normal_available_cash -= actual_invest  # ä¿®å¤ï¼šæ‰£å‡å¯ç”¨ç°é‡‘
                normal_invested_weeks.add(current_week)
            # ç°é‡‘ä¸è¶³æ—¶åœæ­¢å®šæŠ•
            elif current_week not in normal_invested_weeks and normal_available_cash < invest_amount:
                logs.append(f"âš ï¸ {row['æ—¥æœŸ']} æ™®é€šå®šæŠ•ç°é‡‘ä¸è¶³ï¼ˆå‰©ä½™{normal_available_cash}å…ƒï¼‰ï¼Œåœæ­¢å®šæŠ•")
            
            # æ›´æ–°æ•°æ®ï¼ˆä¿®å¤ï¼šæ€»èµ„äº§åŒ…å«å‰©ä½™ç°é‡‘ï¼‰
            row["æ™®é€šå®šæŠ•æ€»èµ„äº§"] = round_decimal(normal_invest_shares * row["æ”¶ç›˜ä»·"] + normal_available_cash, 2)
            row["æ™®é€šå®šæŠ•ç´¯è®¡æŠ•å…¥"] = round_decimal(normal_invest_total, 2)
            row["æ™®é€šå®šæŠ•ç´¯è®¡æ”¶ç›Š"] = round_decimal(row["æ™®é€šå®šæŠ•æ€»èµ„äº§"] - initial_capital, 2)
            row["æ™®é€šå®šæŠ•æ”¶ç›Šç‡"] = round_decimal(
                row["æ™®é€šå®šæŠ•ç´¯è®¡æ”¶ç›Š"] / normal_invest_total * 100 if normal_invest_total > 0 else 0, 2
            )
        logs.append(f"âœ… æ™®é€šå®šæŠ•ç­–ç•¥ï¼šç´¯è®¡æŠ•å…¥{normal_invest_total}å…ƒï¼Œå‰©ä½™ç°é‡‘{normal_available_cash}å…ƒï¼Œæœ€ç»ˆæŒä»“{round_decimal(normal_invest_shares, 2)}è‚¡")
        
        # 3. åº•ä»“+å®šæŠ•ç­–ç•¥
        base_shares = 0.0
        float_shares = 0.0
        base_cash = initial_capital
        base_amount = initial_capital * base_ratio
        base_shares = (base_amount * (1 - fee_rate)) / data[0]["æ”¶ç›˜ä»·"]
        base_cash -= base_amount
        base_total_invest = base_amount
        base_invested_weeks = set()
        
        for row in data:
            row_date = to_valid_date(row["æ—¥æœŸ"])
            current_week = get_iso_week(row_date)
            
            if current_week not in base_invested_weeks and base_cash >= invest_amount:
                base_total_invest += invest_amount
                buy_amount = invest_amount * (1 - fee_rate)
                float_shares += buy_amount / row["æ”¶ç›˜ä»·"]
                base_cash -= invest_amount
                base_invested_weeks.add(current_week)
            
            total_shares = base_shares + float_shares
            row["åº•ä»“å®šæŠ•æ€»èµ„äº§"] = round_decimal(total_shares * row["æ”¶ç›˜ä»·"] + base_cash, 2)
            row["åº•ä»“å®šæŠ•ç´¯è®¡æŠ•å…¥"] = round_decimal(base_total_invest, 2)
            row["åº•ä»“å®šæŠ•ç´¯è®¡æ”¶ç›Š"] = round_decimal(row["åº•ä»“å®šæŠ•æ€»èµ„äº§"] - initial_capital, 2)
            row["åº•ä»“å®šæŠ•æ”¶ç›Šç‡"] = round_decimal(
                row["åº•ä»“å®šæŠ•ç´¯è®¡æ”¶ç›Š"] / initial_capital * 100, 2
            )
        logs.append(f"âœ… åº•ä»“+å®šæŠ•ç­–ç•¥ï¼šåˆå§‹åº•ä»“{round_decimal(base_shares, 2)}è‚¡")
        
        # 4. ä¼°å€¼æ­¢ç›ˆç­–ç•¥ï¼ˆä¿®å¤ï¼šå¢åŠ æ€»æŠ•å…¥ä¸Šé™ï¼Œä»…ç”¨è‡ªæœ‰èµ„é‡‘ï¼‰
        valuation_base_shares = 0.0
        valuation_float_shares = 0.0
        valuation_cash = initial_capital
        valuation_base_amount = initial_capital * 0.5
        # æ–°å¢ï¼šé™åˆ¶åº•ä»“é‡‘é¢ä¸è¶…åˆå§‹ç°é‡‘
        valuation_base_amount = min(valuation_base_amount, valuation_cash)
        valuation_base_shares = (valuation_base_amount * (1 - fee_rate)) / data[0]["æ”¶ç›˜ä»·"]
        valuation_cash -= valuation_base_amount
        valuation_total_invest = valuation_base_amount
        buy_sell_markers = []
        
        for row in data:
            pe_quantile = row["PEåˆ†ä½ç‚¹"]
            current_price = row["æ”¶ç›˜ä»·"]
            row["ä¹°å–æ ‡è®°"] = ""
            
            # ä»“ä½è°ƒæ•´ï¼ˆä¿®å¤ï¼šå¢åŠ æ€»æŠ•å…¥ä¸è¶…åˆå§‹æœ¬é‡‘é™åˆ¶ï¼‰
            if pe_quantile < pe_lower_quantile and valuation_cash > 0:
                # æ–°å¢ï¼šç¡®ä¿ä¹°å…¥åæ€»æŠ•å…¥â‰¤åˆå§‹æœ¬é‡‘
                max_buyable = initial_capital - valuation_total_invest
                if max_buyable <= 0:
                    row["ä¼°å€¼æ­¢ç›ˆä¿¡å·"] = "æ»¡ä»“ï¼ˆæ€»æŠ•å…¥å·²è¾¾æœ¬é‡‘ä¸Šé™ï¼‰"
                else:
                    actual_buy = min(valuation_cash, max_buyable)  # ä¿®å¤ï¼šä¸è¶…å‰©ä½™ç°é‡‘+æœ¬é‡‘ä¸Šé™
                    buy_amount = actual_buy * (1 - fee_rate)
                    valuation_float_shares += buy_amount / current_price
                    valuation_total_invest += actual_buy
                    valuation_cash -= actual_buy
                    row["ä¼°å€¼æ­¢ç›ˆä¿¡å·"] = "åŠ ä»“ï¼ˆPEåˆ†ä½ç‚¹<30%ï¼‰"
                    row["ä¹°å–æ ‡è®°"] = "buy"
                    buy_sell_markers.append({
                        "date": row["æ—¥æœŸ"],
                        "type": "buy",
                        "buyOnceReturn": row["ä¸€æ¬¡æ€§ä¹°å…¥æ”¶ç›Šç‡"],
                        "normalReturn": row["æ™®é€šå®šæŠ•æ”¶ç›Šç‡"],
                        "baseReturn": row["åº•ä»“å®šæŠ•æ”¶ç›Šç‡"],
                        "valuationReturn": round_decimal(
                            (row["ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§"] - initial_capital) / initial_capital * 100, 2
                        )
                    })
                    logs.append(f"ğŸ“ˆ {row['æ—¥æœŸ']} PEåˆ†ä½ç‚¹{pe_quantile}%ï¼ŒåŠ ä»“{actual_buy}å…ƒï¼ˆå‰©ä½™ç°é‡‘{valuation_cash}å…ƒï¼‰")
            
            elif pe_quantile > pe_upper_quantile and valuation_float_shares > 0:
                sell_amount = valuation_float_shares * current_price * (1 - fee_rate)
                valuation_cash += sell_amount
                valuation_float_shares = 0
                row["ä¼°å€¼æ­¢ç›ˆä¿¡å·"] = "å‡ä»“ï¼ˆPEåˆ†ä½ç‚¹>70%ï¼‰"
                row["ä¹°å–æ ‡è®°"] = "sell"
                buy_sell_markers.append({
                    "date": row["æ—¥æœŸ"],
                    "type": "sell",
                    "buyOnceReturn": row["ä¸€æ¬¡æ€§ä¹°å…¥æ”¶ç›Šç‡"],
                    "normalReturn": row["æ™®é€šå®šæŠ•æ”¶ç›Šç‡"],
                    "baseReturn": row["åº•ä»“å®šæŠ•æ”¶ç›Šç‡"],
                    "valuationReturn": round_decimal(
                        (row["ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§"] - initial_capital) / initial_capital * 100, 2
                    )
                })
                logs.append(f"ğŸ“‰ {row['æ—¥æœŸ']} PEåˆ†ä½ç‚¹{pe_quantile}%ï¼Œå‡ä»“å–å‡ºï¼Œç°é‡‘å¢åŠ è‡³{valuation_cash}å…ƒ")
            
            else:
                row["ä¼°å€¼æ­¢ç›ˆä¿¡å·"] = "æŒæœ‰åº•ä»“ï¼ˆPEåˆ†ä½ç‚¹æ­£å¸¸ï¼‰" if pe_quantile > 0 else "æ— PEæ•°æ®"
            
            # æ›´æ–°ä¼°å€¼æ­¢ç›ˆæ•°æ®
            total_valuation_shares = valuation_base_shares + valuation_float_shares
            valuation_position_value = total_valuation_shares * current_price
            row["ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§"] = round_decimal(valuation_position_value + valuation_cash, 2)
            row["ä¼°å€¼æ­¢ç›ˆç´¯è®¡æŠ•å…¥"] = round_decimal(valuation_total_invest, 2)
            row["ä¼°å€¼æ­¢ç›ˆç´¯è®¡æ”¶ç›Š"] = round_decimal(row["ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§"] - initial_capital, 2)
            row["ä¼°å€¼æ­¢ç›ˆæ€»æ”¶ç›Šç‡"] = round_decimal(
                (row["ä¼°å€¼æ­¢ç›ˆç´¯è®¡æ”¶ç›Š"] / valuation_total_invest * 100) if valuation_total_invest > 0 else 0, 2
            )
            row["ä¼°å€¼æ­¢ç›ˆä»“ä½"] = round_decimal(
                (valuation_position_value / row["ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§"] * 100) if row["ä¼°å€¼æ­¢ç›ˆæ€»èµ„äº§"] > 0 else 0, 2
            )
        
        logs.append(f"âœ… åŠ¨æ€ä¼°å€¼æ­¢ç›ˆç­–ç•¥è®¡ç®—å®Œæˆï¼Œæœ€ç»ˆä»“ä½{data[-1]['ä¼°å€¼æ­¢ç›ˆä»“ä½']}%")
        
        # ç”Ÿæˆå›¾è¡¨æ•°æ®
        chart_data = generate_chart_data(data, buy_sell_markers)
        
        # æœ€ç»ˆç»“æœæ±‡æ€»
        final_row = data[-1]
        result_summary = {
            "ä¸€æ¬¡æ€§ä¹°å…¥": {
                "æ”¶ç›Šç‡": f"{final_row['ä¸€æ¬¡æ€§ä¹°å…¥æ”¶ç›Šç‡']}%",
                "æ”¶ç›Šé‡‘é¢": f"{final_row['ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æ”¶ç›Š']}å…ƒ"
            },
            "æ™®é€šå®šæŠ•": {
                "æ”¶ç›Šç‡": f"{final_row['æ™®é€šå®šæŠ•æ”¶ç›Šç‡']}%",
                "æ”¶ç›Šé‡‘é¢": f"{final_row['æ™®é€šå®šæŠ•ç´¯è®¡æ”¶ç›Š']}å…ƒ"
            },
            "åº•ä»“+å®šæŠ•": {
                "æ”¶ç›Šç‡": f"{final_row['åº•ä»“å®šæŠ•æ”¶ç›Šç‡']}%",
                "æ”¶ç›Šé‡‘é¢": f"{final_row['åº•ä»“å®šæŠ•ç´¯è®¡æ”¶ç›Š']}å…ƒ"
            },
            "ä¼°å€¼æ­¢ç›ˆ": {
                "æ”¶ç›Šç‡": f"{final_row['ä¼°å€¼æ­¢ç›ˆæ€»æ”¶ç›Šç‡']}%",
                "æ”¶ç›Šé‡‘é¢": f"{final_row['ä¼°å€¼æ­¢ç›ˆç´¯è®¡æ”¶ç›Š']}å…ƒ",
                "æœ€ç»ˆä»“ä½": f"{final_row['ä¼°å€¼æ­¢ç›ˆä»“ä½']}%"
            }
        }
        
        return {
            "success": True,
            "logs": logs,
            "result_summary": result_summary,
            "chart_data": chart_data
        }
    
    except Exception as e:
        logs.append(f"âŒ ç­–ç•¥è®¡ç®—å¤±è´¥ï¼š{str(e)}")
        logger.error(f"ç­–ç•¥è®¡ç®—å¼‚å¸¸ï¼š{e}", exc_info=True)
        return {
            "success": False,
            "logs": logs,
            "error": str(e)
        }

def generate_chart_data(data, buy_sell_markers):
    """ç”Ÿæˆå‰ç«¯Plotlyå›¾è¡¨æ•°æ®"""
    # æå–åŸºç¡€æ•°æ®
    dates = [row["æ—¥æœŸ"] for row in data]
    prices = [row["æ”¶ç›˜ä»·"] for row in data]
    pe_quantiles = [row["PEåˆ†ä½ç‚¹"] for row in data]
    eps_ttm_values = [row["æ¯è‚¡ç›ˆåˆ©TTM"] if row["æ¯è‚¡ç›ˆåˆ©TTM"] is not None else 0 for row in data]
    pe_values = [row["PE"] for row in data]
    
    # æ”¶ç›Šç‡æ•°æ®
    buy_once_return = [row["ä¸€æ¬¡æ€§ä¹°å…¥æ”¶ç›Šç‡"] for row in data]
    normal_return = [row["æ™®é€šå®šæŠ•æ”¶ç›Šç‡"] for row in data]
    base_return = [row["åº•ä»“å®šæŠ•æ”¶ç›Šç‡"] for row in data]
    valuation_return = [row["ä¼°å€¼æ­¢ç›ˆæ€»æ”¶ç›Šç‡"] for row in data]
    
    # ç´¯è®¡æŠ•å…¥/æ”¶ç›Šæ•°æ®
    buy_once_invest = [row["ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æŠ•å…¥"] for row in data]
    normal_invest = [row["æ™®é€šå®šæŠ•ç´¯è®¡æŠ•å…¥"] for row in data]
    base_invest = [row["åº•ä»“å®šæŠ•ç´¯è®¡æŠ•å…¥"] for row in data]
    valuation_invest = [row["ä¼°å€¼æ­¢ç›ˆç´¯è®¡æŠ•å…¥"] for row in data]
    
    buy_once_profit = [row["ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æ”¶ç›Š"] for row in data]
    normal_profit = [row["æ™®é€šå®šæŠ•ç´¯è®¡æ”¶ç›Š"] for row in data]
    base_profit = [row["åº•ä»“å®šæŠ•ç´¯è®¡æ”¶ç›Š"] for row in data]
    valuation_profit = [row["ä¼°å€¼æ­¢ç›ˆç´¯è®¡æ”¶ç›Š"] for row in data]
    
    # å›¾è¡¨1ï¼šè‚¡ä»· vs PEåˆ†ä½ç‚¹ vs æ¯è‚¡ç›ˆåˆ©TTM
    chart1 = {
        "traces": [
            {
                "x": dates,
                "y": prices,
                "name": "è‚¡ä»·ï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#1f77b4", "width": 2},
                "yaxis": "y1"
            },
            {
                "x": dates,
                "y": pe_quantiles,
                "name": "PEåˆ†ä½ç‚¹ï¼ˆ%ï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#d62728", "width": 2, "dash": "dash"},
                "yaxis": "y2"
            },
            {
                "x": dates,
                "y": eps_ttm_values,
                "name": "æ¯è‚¡ç›ˆåˆ©TTMï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#2ca02c", "width": 2, "dash": "dot"},
                "yaxis": "y2"
            },
            {
                "x": dates,
                "y": [30]*len(dates),
                "name": "PEä¸‹é™é˜ˆå€¼",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#2ca02c", "width": 1, "dash": "dot"},
                "yaxis": "y2"
            },
            {
                "x": dates,
                "y": [70]*len(dates),
                "name": "PEä¸Šé™é˜ˆå€¼",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#ff7f0e", "width": 1, "dash": "dot"},
                "yaxis": "y2"
            }
        ],
        "layout": {
            "title": "è‚¡ä»·èµ°åŠ¿ã€PEåˆ†ä½ç‚¹ä¸æ¯è‚¡ç›ˆåˆ©TTM",
            "xaxis": {
                "title": "æ—¥æœŸ",
                "type": "date",
                "tickformat": "%Y-%m-%d",
                "showgrid": True,
                "gridcolor": "#e0e0e0"
            },
            "yaxis": {
                "title": "è‚¡ä»·ï¼ˆå…ƒï¼‰",
                "side": "left",
                "showgrid": True,
                "gridcolor": "#e0e0e0"
            },
            "yaxis2": {
                "title": "PEåˆ†ä½ç‚¹ï¼ˆ%ï¼‰/ æ¯è‚¡ç›ˆåˆ©TTMï¼ˆå…ƒï¼‰",
                "overlaying": "y",
                "side": "right",
                "showgrid": False
            },
            "legend": {"x": 0, "y": 1},
            "hovermode": "x unified",
            "height": 600
        }
    }
    
    # å›¾è¡¨2ï¼šæ”¶ç›Šç‡ï¼ˆå«ä¹°å–ç‚¹ï¼‰
    chart2_traces = [
        {
            "x": dates,
            "y": buy_once_return,
            "name": "ä¸€æ¬¡æ€§ä¹°å…¥ï¼ˆæ€»æ”¶ç›Šç‡%ï¼‰",
            "type": "scatter",
            "mode": "lines",
            "line": {"color": "#ff7f0e", "width": 2}
        },
        {
            "x": dates,
            "y": normal_return,
            "name": "æ™®é€šå®šæŠ•ï¼ˆæ€»æ”¶ç›Šç‡%ï¼‰",
            "type": "scatter",
            "mode": "lines",
            "line": {"color": "#9467bd", "width": 2}
        },
        {
            "x": dates,
            "y": base_return,
            "name": "åº•ä»“+å®šæŠ•ï¼ˆæ€»æ”¶ç›Šç‡%ï¼‰",
            "type": "scatter",
            "mode": "lines",
            "line": {"color": "#2ca02c", "width": 2}
        },
        {
            "x": dates,
            "y": valuation_return,
            "name": "ä¼°å€¼æ­¢ç›ˆï¼ˆæ€»æ”¶ç›Šç‡%ï¼‰",
            "type": "scatter",
            "mode": "lines",
            "line": {"color": "#d62728", "width": 2}
        }
    ]
    
    # æ·»åŠ ä¹°å–ç‚¹æ ‡è®°
    if buy_sell_markers:
        buy_dates = [m["date"] for m in buy_sell_markers if m["type"] == "buy"]
        buy_vals = [m["valuationReturn"] for m in buy_sell_markers if m["type"] == "buy"]
        sell_dates = [m["date"] for m in buy_sell_markers if m["type"] == "sell"]
        sell_vals = [m["valuationReturn"] for m in buy_sell_markers if m["type"] == "sell"]
        
        chart2_traces.append({
            "x": buy_dates,
            "y": buy_vals,
            "name": "ä¼°å€¼æ­¢ç›ˆ-ä¹°å…¥ç‚¹",
            "type": "scatter",
            "mode": "markers",
            "marker": {"color": "#d62728", "size": 12, "symbol": "triangle-up"},
            "showlegend": True
        })
        
        chart2_traces.append({
            "x": sell_dates,
            "y": sell_vals,
            "name": "ä¼°å€¼æ­¢ç›ˆ-å–å‡ºç‚¹",
            "type": "scatter",
            "mode": "markers",
            "marker": {"color": "#d62728", "size": 12, "symbol": "triangle-down"},
            "showlegend": True
        })
    
    chart2 = {
        "traces": chart2_traces,
        "layout": {
            "title": "è‚¡ç¥¨å®šæŠ•ç­–ç•¥æ”¶ç›Šç‡ï¼ˆå«ä¹°å–ç‚¹æ ‡æ³¨ï¼‰",
            "xaxis": {
                "title": "æ—¥æœŸ",
                "type": "date",
                "tickformat": "%Y-%m-%d",
                "showgrid": True,
                "gridcolor": "#e0e0e0"
            },
            "yaxis": {
                "title": "æ”¶ç›Šç‡ï¼ˆ%ï¼‰",
                "showgrid": True,
                "gridcolor": "#e0e0e0"
            },
            "legend": {"x": 0, "y": 1},
            "hovermode": "x unified",
            "height": 600
        }
    }
    
    # å›¾è¡¨3ï¼šç´¯è®¡æŠ•å…¥ vs ç´¯è®¡æ”¶ç›Š
    chart3 = {
        "traces": [
            # ç´¯è®¡æŠ•å…¥
            {
                "x": dates,
                "y": buy_once_invest,
                "name": "ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æŠ•å…¥ï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#ff7f0e", "width": 2},
                "yaxis": "y1"
            },
            {
                "x": dates,
                "y": normal_invest,
                "name": "æ™®é€šå®šæŠ•ç´¯è®¡æŠ•å…¥ï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#9467bd", "width": 2},
                "yaxis": "y1"
            },
            {
                "x": dates,
                "y": base_invest,
                "name": "åº•ä»“å®šæŠ•ç´¯è®¡æŠ•å…¥ï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#2ca02c", "width": 2},
                "yaxis": "y1"
            },
            {
                "x": dates,
                "y": valuation_invest,
                "name": "ä¼°å€¼æ­¢ç›ˆç´¯è®¡æŠ•å…¥ï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#d62728", "width": 2},
                "yaxis": "y1"
            },
            # ç´¯è®¡æ”¶ç›Š
            {
                "x": dates,
                "y": buy_once_profit,
                "name": "ä¸€æ¬¡æ€§ä¹°å…¥ç´¯è®¡æ”¶ç›Šï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#ff7f0e", "width": 2, "dash": "dash"},
                "yaxis": "y2"
            },
            {
                "x": dates,
                "y": normal_profit,
                "name": "æ™®é€šå®šæŠ•ç´¯è®¡æ”¶ç›Šï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#9467bd", "width": 2, "dash": "dash"},
                "yaxis": "y2"
            },
            {
                "x": dates,
                "y": base_profit,
                "name": "åº•ä»“å®šæŠ•ç´¯è®¡æ”¶ç›Šï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#2ca02c", "width": 2, "dash": "dash"},
                "yaxis": "y2"
            },
            {
                "x": dates,
                "y": valuation_profit,
                "name": "ä¼°å€¼æ­¢ç›ˆç´¯è®¡æ”¶ç›Šï¼ˆå…ƒï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#d62728", "width": 2, "dash": "dash"},
                "yaxis": "y2"
            }
        ],
        "layout": {
            "title": "ç´¯è®¡æŠ•å…¥é‡‘é¢ vs ç´¯è®¡æ”¶ç›Š",
            "xaxis": {
                "title": "æ—¥æœŸ",
                "type": "date",
                "tickformat": "%Y-%m-%d",
                "showgrid": True,
                "gridcolor": "#e0e0e0"
            },
            "yaxis": {
                "title": "ç´¯è®¡æŠ•å…¥é‡‘é¢ï¼ˆå…ƒï¼‰",
                "side": "left",
                "showgrid": True,
                "gridcolor": "#e0e0e0"
            },
            "yaxis2": {
                "title": "ç´¯è®¡æ”¶ç›Šï¼ˆå…ƒï¼‰",
                "overlaying": "y",
                "side": "right",
                "showgrid": False
            },
            "legend": {"x": 0, "y": 1},
            "hovermode": "x unified",
            "height": 600
        }
    }
    
    # å›¾è¡¨4ï¼šPEå€¼èµ°åŠ¿
    pe_mean = np.mean([p for p in pe_values if p > 0]) if pe_values else 0
    chart4 = {
        "traces": [
            {
                "x": dates,
                "y": pe_values,
                "name": "PE(TTM)å€¼",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#1f77b4", "width": 2}
            },
            {
                "x": dates,
                "y": [pe_mean]*len(dates),
                "name": f"PEå‡å€¼ï¼ˆ{round_decimal(pe_mean, 2)}ï¼‰",
                "type": "scatter",
                "mode": "lines",
                "line": {"color": "#ff7f0e", "width": 1, "dash": "dot"}
            }
        ],
        "layout": {
            "title": "PE(TTM)å€¼èµ°åŠ¿ï¼ˆå«å‡å€¼å‚è€ƒï¼‰",
            "xaxis": {
                "title": "æ—¥æœŸ",
                "type": "date",
                "tickformat": "%Y-%m-%d"
            },
            "yaxis": {
                "title": "PE(TTM)å€¼"
            },
            "legend": {"x": 0, "y": 1},
            "hovermode": "x unified",
            "height": 600
        }
    }
    
    return {
        "chart1": chart1,
        "chart2": chart2,
        "chart3": chart3,
        "chart4": chart4
    }

# ====================== 8. APIæ¥å£ ======================
@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        "code": 200,
        "msg": "æœåŠ¡å™¨æ­£å¸¸",
        "data": {"time": datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    })

@app.route('/api/stock_names', methods=['GET'])
def api_stock_names():
    """è·å–æ‰€æœ‰è‚¡ç¥¨åç§°åˆ—è¡¨"""
    return jsonify({"code": 200, "msg": "success", "data": list(STOCK_NAME_MAP.keys())})

@app.route('/api/stock_by_name', methods=['GET'])
def api_stock_by_name():
    """æ¨¡ç³Šåç§°æŸ¥è¯¢è‚¡ç¥¨"""
    try:
        input_name = request.args.get('name', '').strip()
        start_date = request.args.get('start', datetime.datetime.now().strftime('%Y-%m-%d'))
        end_date = request.args.get('end', datetime.datetime.now().strftime('%Y-%m-%d'))
        
        if not input_name:
            return jsonify({
                "code": 400,
                "msg": "è‚¡ç¥¨åç§°ä¸èƒ½ä¸ºç©º",
                "data": []
            })
        
        matched_stocks = fuzzy_match_stock_by_name(input_name)
        if not matched_stocks:
            return jsonify({
                "code": 404,
                "msg": f"æœªæ‰¾åˆ°ã€Œ{input_name}ã€ç›¸å…³çš„è‚¡ç¥¨",
                "data": []
            })
        
        result_list = []
        for stock in matched_stocks:
            stock_data = get_stock_data(stock["code"], start_date, end_date, stock["is_hk"])
            result_list.append({
                "name": stock["name"],
                "code": stock["code"],
                "is_hk": stock["is_hk"],
                "stock_data": stock_data
            })
        
        return jsonify({
            "code": 200,
            "msg": f"æˆåŠŸåŒ¹é…{len(result_list)}åªè‚¡ç¥¨",
            "data": result_list
        })
    
    except Exception as e:
        logger.error(f"æ¨¡ç³Šåç§°æŸ¥è¯¢æ¥å£å¼‚å¸¸ï¼š{e}", exc_info=True)
        return jsonify({
            "code": 500,
            "msg": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}",
            "data": []
        })

@app.route('/api/stock_by_letter', methods=['GET'])
def api_stock_by_letter():
    """æ‹¼éŸ³é¦–å­—æ¯æŸ¥è¯¢è‚¡ç¥¨"""
    try:
        input_letter = request.args.get('letter', '').strip()
        if not input_letter:
            return jsonify({
                "code": 400,
                "msg": "é¦–å­—æ¯ä¸èƒ½ä¸ºç©º",
                "data": []
            })
        
        matched_stocks = match_stock_by_first_letter(input_letter)
        return jsonify({
            "code": 200,
            "msg": f"æˆåŠŸåŒ¹é…{len(matched_stocks)}åªè‚¡ç¥¨",
            "data": matched_stocks
        })
    
    except Exception as e:
        logger.error(f"é¦–å­—æ¯æŸ¥è¯¢æ¥å£å¼‚å¸¸ï¼š{e}", exc_info=True)
        return jsonify({
            "code": 500,
            "msg": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}",
            "data": []
        })

@app.route('/api/stock_name_by_code', methods=['GET'])
def api_stock_name_by_code():
    """æ ¹æ®ä»£ç è·å–è‚¡ç¥¨åç§°"""
    try:
        stock_code = request.args.get('code', '').strip()
        if not stock_code:
            return jsonify({
                "code": 400,
                "msg": "è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º",
                "data": {"name": "", "code": ""}
            })
        
        matched_code, is_hk = match_stock_code(stock_code)
        if not matched_code:
            return jsonify({
                "code": 404,
                "msg": f"æœªæ‰¾åˆ°'{stock_code}'å¯¹åº”çš„è‚¡ç¥¨ä»£ç ",
                "data": {"name": "", "code": ""}
            })
        
        # ä¸‰çº§åç§°è·å–
        stock_name = CODE_TO_STOCK_NAME.get(matched_code)
        if not stock_name and not is_hk:
            stock_name = get_stock_name_from_baostock(matched_code)
        if not stock_name:
            stock_name = f"æœªçŸ¥è‚¡ç¥¨({matched_code})"
        
        return jsonify({
            "code": 200,
            "msg": "æˆåŠŸè·å–è‚¡ç¥¨åç§°",
            "data": {
                "name": stock_name,
                "code": matched_code,
                "is_hk": is_hk
            }
        })
    
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨åç§°æ¥å£å¼‚å¸¸ï¼š{e}", exc_info=True)
        return jsonify({
            "code": 500,
            "msg": f"æ¥å£å¼‚å¸¸ï¼š{str(e)}",
            "data": {"name": "", "code": "", "is_hk": False}
        })

@app.route('/api/stock_info', methods=['GET'])
def api_stock_info():
    """é€šç”¨è‚¡ç¥¨ä¿¡æ¯æŸ¥è¯¢ï¼ˆä»£ç /åç§°/é¦–å­—æ¯ï¼‰"""
    try:
        input_str = request.args.get('input', '').strip()
        if not input_str:
            return jsonify({
                "code": 400,
                "msg": "è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼ˆæ”¯æŒè‚¡ç¥¨åç§°/ä»£ç /é¦–å­—æ¯ï¼‰",
                "data": {"name": "", "code": "", "is_hk": False, "first_letter": ""}
            })
        
        matched_code, is_hk = match_stock_code(input_str)
        if not matched_code:
            return jsonify({
                "code": 404,
                "msg": f"æœªæ‰¾åˆ°ã€Œ{input_str}ã€å¯¹åº”çš„è‚¡ç¥¨ä¿¡æ¯",
                "data": {"name": "", "code": "", "is_hk": False, "first_letter": ""}
            })
        
        # ä¸‰çº§åç§°è·å–
        stock_name = CODE_TO_STOCK_NAME.get(matched_code)
        if not stock_name and not is_hk:
            stock_name = get_stock_name_from_baostock(matched_code)
        if not stock_name:
            stock_name = f"æœªçŸ¥è‚¡ç¥¨({matched_code})"
        
        # è·å–é¦–å­—æ¯
        first_letter = get_pinyin_first_letter(stock_name)
        
        return jsonify({
            "code": 200,
            "msg": "æˆåŠŸè·å–è‚¡ç¥¨ä¿¡æ¯",
            "data": {
                "name": stock_name,
                "code": matched_code,
                "is_hk": is_hk,
                "first_letter": first_letter
            }
        })
    
    except Exception as e:
        logger.error(f"é€šç”¨è‚¡ç¥¨ä¿¡æ¯æ¥å£å¼‚å¸¸ï¼š{e}", exc_info=True)
        return jsonify({
            "code": 500,
            "msg": f"æ¥å£å¼‚å¸¸ï¼š{str(e)}",
            "data": {"name": "", "code": "", "is_hk": False, "first_letter": ""}
        })

@app.route('/api/stock_data', methods=['GET'])
def api_stock_data():
    """æ ¸å¿ƒæ¥å£ï¼šè·å–è‚¡ç¥¨åŸºç¡€æ•°æ®"""
    try:
        stock_input = request.args.get('code', '600519')
        start_date = request.args.get('start_date', '2023-01-01')
        end_date = request.args.get('end_date', datetime.datetime.now().strftime('%Y-%m-%d'))
        
        logger.info(f"æ”¶åˆ°è¯·æ±‚ï¼šcode={stock_input}, start={start_date}, end={end_date}")
        
        stock_code, is_hk = match_stock_code(stock_input)
        if not stock_code:
            return jsonify({"code": 400, "msg": "æœªæ‰¾åˆ°åŒ¹é…çš„è‚¡ç¥¨", "data": [], "stock_name": "", "stock_code": ""})
        
        # ä¸‰çº§åç§°è·å–
        stock_name = CODE_TO_STOCK_NAME.get(stock_code)
        if not stock_name and not is_hk:
            stock_name = get_stock_name_from_baostock(stock_code)
        if not stock_name:
            stock_name = f"æœªçŸ¥è‚¡ç¥¨({stock_code})"
        
        result = get_stock_data(stock_code, start_date, end_date, is_hk)
        result["stock_name"] = stock_name
        result["stock_code"] = stock_code
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"æ¥å£å¼‚å¸¸ï¼š{e}", exc_info=True)
        return jsonify({"code": 500, "msg": f"æ¥å£å¼‚å¸¸ï¼š{str(e)}", "data": [], "stock_name": "", "stock_code": ""})

@app.route('/api/analyze_strategy', methods=['POST'])
def api_analyze_strategy():
    """æ ¸å¿ƒæ¥å£ï¼šå®šæŠ•ç­–ç•¥åˆ†æ"""
    try:
        params = request.json
        logger.info(f"æ”¶åˆ°ç­–ç•¥åˆ†æè¯·æ±‚ï¼š{params}")
        
        # è·å–åŸºç¡€è‚¡ç¥¨æ•°æ®
        stock_code, is_hk = match_stock_code(params.get('stockCode', '600519'))
        if not stock_code:
            return jsonify({
                "success": False,
                "logs": ["âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è‚¡ç¥¨"],
                "error": "æœªæ‰¾åˆ°åŒ¹é…çš„è‚¡ç¥¨"
            })
        
        # ä¸‰çº§åç§°è·å–
        stock_name = CODE_TO_STOCK_NAME.get(stock_code)
        if not stock_name and not is_hk:
            stock_name = get_stock_name_from_baostock(stock_code)
        if not stock_name:
            stock_name = f"æœªçŸ¥è‚¡ç¥¨({stock_code})"
        
        stock_data_result = get_stock_data(
            stock_code,
            params.get('baostockStartDate', '2023-01-01'),
            params.get('baostockEndDate', datetime.datetime.now().strftime('%Y-%m-%d')),
            is_hk
        )
        
        if stock_data_result["code"] != 200 or not stock_data_result["data"]:
            return jsonify({
                "success": False,
                "logs": [f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥ï¼š{stock_data_result['msg']}"],
                "error": stock_data_result["msg"]
            })
        
        # æ‰§è¡Œç­–ç•¥è®¡ç®—
        strategy_result = run_strategy(stock_data_result["data"], params)
        strategy_result["stock_name"] = stock_name
        strategy_result["stock_code"] = stock_code
        
        return jsonify(strategy_result)
    
    except Exception as e:
        logger.error(f"åˆ†ææ¥å£å¼‚å¸¸ï¼š{e}", exc_info=True)
        return jsonify({
            "success": False,
            "logs": [f"âŒ æ¥å£å¼‚å¸¸ï¼š{str(e)}"],
            "error": str(e)
        })

@app.route('/api/login', methods=['POST'])
def api_login():
    """Mockç™»å½•æ¥å£"""
    try:
        data = request.json
        username = data.get('username', '')
        password = data.get('password', '')
        
        logger.info(f"Mockç™»å½•è¯·æ±‚ï¼šç”¨æˆ·å={username}")
        return jsonify({
            "code": 200,
            "msg": "ç™»å½•æˆåŠŸï¼ˆé¢„ç•™åŠŸèƒ½ï¼‰",
            "data": {
                "token": f"mock_token_{username}_{int(time.time())}",
                "username": username
            }
        })
    except Exception as e:
        logger.error(f"Mockç™»å½•æ¥å£å¼‚å¸¸ï¼š{e}")
        return jsonify({
            "code": 500,
            "msg": "ç™»å½•å¤±è´¥ï¼ˆé¢„ç•™åŠŸèƒ½ï¼‰",
            "data": {}
        })

# ====================== 9. å¯åŠ¨é…ç½®ï¼ˆå…¼å®¹æœ¬åœ°/å®å¡”ï¼‰ ======================
if __name__ == '__main__':
    # é¢„è¿æ¥Baostockæµ‹è¯•
    try:
        test_login = bs.login()
        if test_login.error_code == '0':
            logger.info("Baostocké¢„è¿æ¥æˆåŠŸ")
            bs.logout()
        else:
            logger.warning(f"Baostocké¢„è¿æ¥å¤±è´¥ï¼š{test_login.error_msg}")
    except Exception as e:
        logger.error(f"Baostocké¢„è¿æ¥å¼‚å¸¸ï¼š{e}")
    
    # å¯åŠ¨æœåŠ¡ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ç”¨uWSGIï¼Œæœ¬åœ°è°ƒè¯•ç”¨è¿™ä¸ªï¼‰
    app.run(
        host='0.0.0.0',    # å…è®¸å¤–éƒ¨è®¿é—®
        port=8002,         # ç«¯å£ï¼ˆå’ŒNginxåå‘ä»£ç†ä¸€è‡´ï¼‰
        debug=False,       # ç”Ÿäº§ç¯å¢ƒå…³é—­debug
        threaded=True,     # å¼€å¯å¤šçº¿ç¨‹
        use_reloader=False # å…³é—­è‡ªåŠ¨é‡è½½
    )